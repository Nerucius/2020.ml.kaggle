{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, Binarizer, MinMaxScaler, \\\n",
    "    QuantileTransformer, StandardScaler, KernelCenterer, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import activations\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['B_OWNPV_CHI2', 'B_IPCHI2_OWNPV', 'B_FDCHI2_OWNPV', 'B_DIRA_OWNPV',\n",
      "       'B_PT', 'Kst_892_0_IP_OWNPV', 'Kst_892_0_cosThetaH', 'Kplus_IP_OWNPV',\n",
      "       'Kplus_P', 'piminus_IP_OWNPV', 'piminus_P', 'gamma_PT', 'piminus_ETA',\n",
      "       'Kplus_ETA', 'signal'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\bin\\python3\\lib\\site-packages\\pandas\\plotting\\_tools.py:307: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "c:\\bin\\python3\\lib\\site-packages\\pandas\\plotting\\_tools.py:307: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
      "c:\\bin\\python3\\lib\\site-packages\\pandas\\plotting\\_tools.py:313: MatplotlibDeprecationWarning: \n",
      "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n",
      "c:\\bin\\python3\\lib\\site-packages\\pandas\\plotting\\_tools.py:313: MatplotlibDeprecationWarning: \n",
      "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
      "  if not layout[ax.rowNum + 1, ax.colNum]:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv', index_col=0)\n",
    "df_eval = pd.read_csv('../data/test.csv', index_col=0)\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "df_eval.columns = df_eval.columns.str.strip()\n",
    "\n",
    "del df['BUTTER']\n",
    "del df_eval['BUTTER']\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "_ = df.hist(bins=20, figsize=[16,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_OWNPV_CHI2</th>\n",
       "      <th>B_IPCHI2_OWNPV</th>\n",
       "      <th>B_FDCHI2_OWNPV</th>\n",
       "      <th>B_DIRA_OWNPV</th>\n",
       "      <th>B_PT</th>\n",
       "      <th>Kst_892_0_IP_OWNPV</th>\n",
       "      <th>Kst_892_0_cosThetaH</th>\n",
       "      <th>Kplus_IP_OWNPV</th>\n",
       "      <th>Kplus_P</th>\n",
       "      <th>piminus_IP_OWNPV</th>\n",
       "      <th>...</th>\n",
       "      <th>piminus_IP_OWNPV__X__piminus_P</th>\n",
       "      <th>gamma_PT__X__piminus_IP_OWNPV</th>\n",
       "      <th>piminus_ETA__X__piminus_IP_OWNPV</th>\n",
       "      <th>Kplus_ETA__X__piminus_IP_OWNPV</th>\n",
       "      <th>gamma_PT__X__piminus_P</th>\n",
       "      <th>piminus_ETA__X__piminus_P</th>\n",
       "      <th>Kplus_ETA__X__piminus_P</th>\n",
       "      <th>gamma_PT__X__piminus_ETA</th>\n",
       "      <th>Kplus_ETA__X__gamma_PT</th>\n",
       "      <th>Kplus_ETA__X__piminus_ETA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.878847</td>\n",
       "      <td>2.662533</td>\n",
       "      <td>2924.690991</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>19085.568945</td>\n",
       "      <td>0.569198</td>\n",
       "      <td>-0.575502</td>\n",
       "      <td>0.581565</td>\n",
       "      <td>66850.893711</td>\n",
       "      <td>0.637969</td>\n",
       "      <td>...</td>\n",
       "      <td>9121.987912</td>\n",
       "      <td>5065.915128</td>\n",
       "      <td>1.676918</td>\n",
       "      <td>1.709831</td>\n",
       "      <td>1.135399e+08</td>\n",
       "      <td>37583.944252</td>\n",
       "      <td>38321.608610</td>\n",
       "      <td>20872.322302</td>\n",
       "      <td>21281.985751</td>\n",
       "      <td>7.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.233566</td>\n",
       "      <td>0.092746</td>\n",
       "      <td>346.948714</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>6631.244546</td>\n",
       "      <td>0.248707</td>\n",
       "      <td>-0.615941</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>39274.475071</td>\n",
       "      <td>0.148815</td>\n",
       "      <td>...</td>\n",
       "      <td>1719.289561</td>\n",
       "      <td>581.077002</td>\n",
       "      <td>0.489975</td>\n",
       "      <td>0.459208</td>\n",
       "      <td>4.511142e+07</td>\n",
       "      <td>38038.833067</td>\n",
       "      <td>35650.222881</td>\n",
       "      <td>12856.177095</td>\n",
       "      <td>12048.886412</td>\n",
       "      <td>10.159856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.113632</td>\n",
       "      <td>2.442423</td>\n",
       "      <td>238.553023</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>7740.918989</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.249383</td>\n",
       "      <td>0.216576</td>\n",
       "      <td>27757.153899</td>\n",
       "      <td>0.249840</td>\n",
       "      <td>...</td>\n",
       "      <td>6016.438340</td>\n",
       "      <td>1183.963190</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.779976</td>\n",
       "      <td>1.141182e+08</td>\n",
       "      <td>82687.022867</td>\n",
       "      <td>75179.239695</td>\n",
       "      <td>16271.818280</td>\n",
       "      <td>14794.376243</td>\n",
       "      <td>10.719615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    B_OWNPV_CHI2  B_IPCHI2_OWNPV  B_FDCHI2_OWNPV  B_DIRA_OWNPV          B_PT  \\\n",
       "Id                                                                             \n",
       "0      28.878847        2.662533     2924.690991      0.999997  19085.568945   \n",
       "1      34.233566        0.092746      346.948714      0.999997   6631.244546   \n",
       "2      36.113632        2.442423      238.553023      0.999986   7740.918989   \n",
       "\n",
       "    Kst_892_0_IP_OWNPV  Kst_892_0_cosThetaH  Kplus_IP_OWNPV       Kplus_P  \\\n",
       "Id                                                                          \n",
       "0             0.569198            -0.575502        0.581565  66850.893711   \n",
       "1             0.248707            -0.615941        0.277898  39274.475071   \n",
       "2             0.222347             0.249383        0.216576  27757.153899   \n",
       "\n",
       "    piminus_IP_OWNPV  ...  piminus_IP_OWNPV__X__piminus_P  \\\n",
       "Id                    ...                                   \n",
       "0           0.637969  ...                     9121.987912   \n",
       "1           0.148815  ...                     1719.289561   \n",
       "2           0.249840  ...                     6016.438340   \n",
       "\n",
       "    gamma_PT__X__piminus_IP_OWNPV  piminus_ETA__X__piminus_IP_OWNPV  \\\n",
       "Id                                                                    \n",
       "0                     5065.915128                          1.676918   \n",
       "1                      581.077002                          0.489975   \n",
       "2                     1183.963190                          0.857868   \n",
       "\n",
       "    Kplus_ETA__X__piminus_IP_OWNPV  gamma_PT__X__piminus_P  \\\n",
       "Id                                                           \n",
       "0                         1.709831            1.135399e+08   \n",
       "1                         0.459208            4.511142e+07   \n",
       "2                         0.779976            1.141182e+08   \n",
       "\n",
       "    piminus_ETA__X__piminus_P  Kplus_ETA__X__piminus_P  \\\n",
       "Id                                                       \n",
       "0                37583.944252             38321.608610   \n",
       "1                38038.833067             35650.222881   \n",
       "2                82687.022867             75179.239695   \n",
       "\n",
       "    gamma_PT__X__piminus_ETA  Kplus_ETA__X__gamma_PT  \\\n",
       "Id                                                     \n",
       "0               20872.322302            21281.985751   \n",
       "1               12856.177095            12048.886412   \n",
       "2               16271.818280            14794.376243   \n",
       "\n",
       "    Kplus_ETA__X__piminus_ETA  \n",
       "Id                             \n",
       "0                    7.044756  \n",
       "1                   10.159856  \n",
       "2                   10.719615  \n",
       "\n",
       "[3 rows x 105 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    df2 = df.copy()\n",
    "    \n",
    "#     Not using EXP / LOG for now\n",
    "#     for col in df.columns[:-1]:\n",
    "#         df2['EXP_'+col] = np.exp(df[col])\n",
    "#         df2['LOG_'+col] = np.log(df[col])\n",
    "\n",
    "    # TODO: idea add a new variable that is the P(signal) for that particular line\n",
    "    # I.e. always P(signal=1)\n",
    "            \n",
    "    done = set()\n",
    "    for col1 in df.columns:\n",
    "        for col2 in df.columns:\n",
    "            colname = '__X__'.join(sorted((col1,col2)))\n",
    "            if col1 != col2 and colname not in done:\n",
    "                df2[colname] = df[col1] * df[col2]\n",
    "                done.add(colname)\n",
    "    \n",
    "    return df2\n",
    "    \n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "    \n",
    "X = preprocess_data(X)\n",
    "X_eval = preprocess_data(df_eval)\n",
    "\n",
    "X[:3]\n",
    "# _ = X.hist(bins=20, figsize=[16,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191395, 105) (21267, 105)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_OWNPV_CHI2</th>\n",
       "      <th>B_IPCHI2_OWNPV</th>\n",
       "      <th>B_FDCHI2_OWNPV</th>\n",
       "      <th>B_DIRA_OWNPV</th>\n",
       "      <th>B_PT</th>\n",
       "      <th>Kst_892_0_IP_OWNPV</th>\n",
       "      <th>Kst_892_0_cosThetaH</th>\n",
       "      <th>Kplus_IP_OWNPV</th>\n",
       "      <th>Kplus_P</th>\n",
       "      <th>piminus_IP_OWNPV</th>\n",
       "      <th>...</th>\n",
       "      <th>piminus_IP_OWNPV__X__piminus_P</th>\n",
       "      <th>gamma_PT__X__piminus_IP_OWNPV</th>\n",
       "      <th>piminus_ETA__X__piminus_IP_OWNPV</th>\n",
       "      <th>Kplus_ETA__X__piminus_IP_OWNPV</th>\n",
       "      <th>gamma_PT__X__piminus_P</th>\n",
       "      <th>piminus_ETA__X__piminus_P</th>\n",
       "      <th>Kplus_ETA__X__piminus_P</th>\n",
       "      <th>gamma_PT__X__piminus_ETA</th>\n",
       "      <th>Kplus_ETA__X__gamma_PT</th>\n",
       "      <th>Kplus_ETA__X__piminus_ETA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135303</td>\n",
       "      <td>-1.063038</td>\n",
       "      <td>-0.068912</td>\n",
       "      <td>0.429082</td>\n",
       "      <td>2.349834</td>\n",
       "      <td>0.061579</td>\n",
       "      <td>1.573659</td>\n",
       "      <td>-0.220530</td>\n",
       "      <td>-0.934353</td>\n",
       "      <td>0.212824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239870</td>\n",
       "      <td>1.423257</td>\n",
       "      <td>-0.214919</td>\n",
       "      <td>-0.233743</td>\n",
       "      <td>0.431639</td>\n",
       "      <td>-0.723915</td>\n",
       "      <td>-0.732474</td>\n",
       "      <td>1.308589</td>\n",
       "      <td>1.251533</td>\n",
       "      <td>-1.620060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.419099</td>\n",
       "      <td>-0.299084</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.494965</td>\n",
       "      <td>-0.218559</td>\n",
       "      <td>0.145170</td>\n",
       "      <td>-1.559699</td>\n",
       "      <td>0.382258</td>\n",
       "      <td>1.097414</td>\n",
       "      <td>-0.609718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.570075</td>\n",
       "      <td>-0.564005</td>\n",
       "      <td>-0.559713</td>\n",
       "      <td>-0.539002</td>\n",
       "      <td>-0.470450</td>\n",
       "      <td>-0.320888</td>\n",
       "      <td>-0.300782</td>\n",
       "      <td>-0.378746</td>\n",
       "      <td>-0.344267</td>\n",
       "      <td>0.348389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.763972</td>\n",
       "      <td>-1.070749</td>\n",
       "      <td>0.496055</td>\n",
       "      <td>0.543126</td>\n",
       "      <td>-0.220517</td>\n",
       "      <td>1.944732</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>1.997508</td>\n",
       "      <td>-0.318689</td>\n",
       "      <td>1.708385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430852</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>1.608116</td>\n",
       "      <td>1.692877</td>\n",
       "      <td>-0.066701</td>\n",
       "      <td>-0.117477</td>\n",
       "      <td>-0.061607</td>\n",
       "      <td>-0.179570</td>\n",
       "      <td>-0.091102</td>\n",
       "      <td>-0.175959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B_OWNPV_CHI2  B_IPCHI2_OWNPV  B_FDCHI2_OWNPV  B_DIRA_OWNPV      B_PT  \\\n",
       "0      0.135303       -1.063038       -0.068912      0.429082  2.349834   \n",
       "1     -0.419099       -0.299084       -0.000083      0.494965 -0.218559   \n",
       "2     -0.763972       -1.070749        0.496055      0.543126 -0.220517   \n",
       "\n",
       "   Kst_892_0_IP_OWNPV  Kst_892_0_cosThetaH  Kplus_IP_OWNPV   Kplus_P  \\\n",
       "0            0.061579             1.573659       -0.220530 -0.934353   \n",
       "1            0.145170            -1.559699        0.382258  1.097414   \n",
       "2            1.944732             0.169434        1.997508 -0.318689   \n",
       "\n",
       "   piminus_IP_OWNPV  ...  piminus_IP_OWNPV__X__piminus_P  \\\n",
       "0          0.212824  ...                       -0.239870   \n",
       "1         -0.609718  ...                       -0.570075   \n",
       "2          1.708385  ...                        1.430852   \n",
       "\n",
       "   gamma_PT__X__piminus_IP_OWNPV  piminus_ETA__X__piminus_IP_OWNPV  \\\n",
       "0                       1.423257                         -0.214919   \n",
       "1                      -0.564005                         -0.559713   \n",
       "2                       0.989975                          1.608116   \n",
       "\n",
       "   Kplus_ETA__X__piminus_IP_OWNPV  gamma_PT__X__piminus_P  \\\n",
       "0                       -0.233743                0.431639   \n",
       "1                       -0.539002               -0.470450   \n",
       "2                        1.692877               -0.066701   \n",
       "\n",
       "   piminus_ETA__X__piminus_P  Kplus_ETA__X__piminus_P  \\\n",
       "0                  -0.723915                -0.732474   \n",
       "1                  -0.320888                -0.300782   \n",
       "2                  -0.117477                -0.061607   \n",
       "\n",
       "   gamma_PT__X__piminus_ETA  Kplus_ETA__X__gamma_PT  Kplus_ETA__X__piminus_ETA  \n",
       "0                  1.308589                1.251533                  -1.620060  \n",
       "1                 -0.378746               -0.344267                   0.348389  \n",
       "2                 -0.179570               -0.091102                  -0.175959  \n",
       "\n",
       "[3 rows x 105 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaler = RobustScaler(quantile_range=(0.1,0.9))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.fillna(0), y, test_size=0.10, random_state=0)\n",
    "X_train = pd.DataFrame(data=scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_train.columns)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import AUC\n",
    "\n",
    "auc = AUC(name='auc')\n",
    "\n",
    "FEATURES = len(X.columns)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(FEATURES*32, input_dim=FEATURES, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(FEATURES*24, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(FEATURES*16, activation='relu'))\n",
    "model.add(Dense(FEATURES*8, activation='relu'))\n",
    "model.add(Dense(FEATURES*4, activation='relu'))\n",
    "model.add(Dense(FEATURES*2, activation='relu'))\n",
    "# OUTPUT\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=50)\n",
    "# Store best model\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_auc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy', auc])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=200,\n",
    "                    callbacks=[es, mc], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14,8])\n",
    "plt.ylim((0.85,0.98))\n",
    "\n",
    "plt.title('AUC for Train / Test')\n",
    "\n",
    "train_acc = history.history['auc']\n",
    "test_acc = history.history['val_auc']\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.plot([max(train_acc)] * len(train_acc))\n",
    "plt.plot([max(test_acc)] * len(test_acc))\n",
    "\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14,8])\n",
    "plt.ylim((0.3,0.5))\n",
    "\n",
    "plt.title('model loss')\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.plot([min(train_loss)] * len(train_loss))\n",
    "plt.plot([min(test_loss)] * len(test_loss))\n",
    "\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all dataset using subsamples K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_dnn_model(X, y, fold):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(14*32, input_dim=14, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(14*24, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(14*16, activation='relu'))\n",
    "    model.add(Dense(14*8, activation='relu'))\n",
    "    model.add(Dense(14*4, activation='relu'))\n",
    "    model.add(Dense(14*2, activation='relu'))\n",
    "    # Output\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Early Stopping\n",
    "    es = EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=20)\n",
    "    mc = ModelCheckpoint(f\"Fold {fold} - best_model.h5\", monitor='val_binary_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=1000, batch_size=200,\n",
    "        callbacks=[es, mc], validation_data=(X_test, y_test), verbose=2)\n",
    "    \n",
    "    return (model, history)\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "models = []\n",
    "\n",
    "X_dnn = df_train[df_train.columns[:-1]]\n",
    "y_dnn = df_train[df_train.columns[-1]]\n",
    "X_dnn = StandardScaler().fit_transform(X_dnn)\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X_dnn, y_dnn)):\n",
    "    X_train, y_train = X_dnn[train], y_dnn[train]\n",
    "    X_test, y_test = X_dnn[test], y_dnn[test]\n",
    "    \n",
    "    try:\n",
    "        open(f\"Fold {fold} - best_model.h5\", 'r')\n",
    "        print(\"Skipping fold\", fold)\n",
    "        continue\n",
    "    except Exception:\n",
    "        print(\"Training fold\", fold)\n",
    "\n",
    "    model, history = train_dnn_model(X_train, y_train, fold)\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "#     print(f\"{fold} AUC Score: \\t {roc_auc_score(y_test, y_hat)}\")\n",
    "    \n",
    "    models += [(fold, model)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict entire dataset one Fold at a time\n",
    "\n",
    "df_dnn = pd.DataFrame(columns=df_train.columns)\n",
    "dnn_preds = []\n",
    "auc_score = 0\n",
    "\n",
    "for fold, (train, test) in enumerate(cv.split(X_dnn, y_dnn)):\n",
    "    y_hat = models[fold][1].predict(X_dnn[test])\n",
    "    dnn_preds += [y_hat.flatten()]\n",
    "    \n",
    "    auc_score += roc_auc_score(y_dnn[test], y_hat) / 10\n",
    "    \n",
    "    print(f\"Predicting fold {fold}, AUC {roc_auc_score(y_dnn[test], y_hat)}\")\n",
    "    \n",
    "    df_dnn = df_dnn.append(df_train.iloc[test])\n",
    "\n",
    "df_dnn['DNN'] = [y for x in dnn_preds for y in x]\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move signal column to last\n",
    "signal = df_dnn.signal\n",
    "del df_dnn['signal']\n",
    "df_dnn['signal'] = signal\n",
    "\n",
    "df_dnn.to_csv('train_dnn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model performance and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy & Area under the ROC curve scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "BEST_MODEL = '2020-10-21T1515 auc0.91941 best_model.h5'\n",
    "#BEST_MODEL = 'best_model.h5'\n",
    "\n",
    "model = load_model(BEST_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.850237457093149\n",
      "Train AUC Score 0.9474683647047341\n",
      "Test AUC Score 0.9195394200156073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "y_hat_train = model.predict(X_train)\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "print('Accuracy', accuracy_score(y_test, Binarizer(threshold=0.5).fit_transform(y_hat_test)))\n",
    "print('Train AUC Score', roc_auc_score(y_train, y_hat_train))\n",
    "print('Test AUC Score', roc_auc_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8700478759653306"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix = pd.read_csv('lgbm_proba.csv', index_col=0)\n",
    "\n",
    "roc_auc_score(y_test, df_mix.lgbm.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-10 0.9195394200156073\n",
      "1-9 0.9200709822334504\n",
      "2-8 0.9195345938094248\n",
      "3-7 0.9181471463342221\n",
      "4-6 0.9158507253336521\n",
      "5-5 0.912429227877643\n",
      "6-4 0.9076294889471248\n",
      "7-3 0.9011432265619785\n",
      "8-2 0.8927644366161693\n",
      "9-1 0.8823997099474884\n",
      "10-0 0.8700478759653306\n"
     ]
    }
   ],
   "source": [
    "df_mix['dnn'] = y_hat_test\n",
    "df_mix['target'] = y_test.values\n",
    "\n",
    "for i in range(11):\n",
    "    col_name = f\"{i}-{10-i}\" \n",
    "    df_mix[col_name] = df_mix['lgbm'] * (i/10.) + df_mix['dnn'] * ((10-i)/10)\n",
    "    \n",
    "    print(col_name, roc_auc_score(y_test.values, df_mix[col_name].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_mix = pd.read_csv('lgbm_eval_proba.csv', index_col=0)\n",
    "df_eval_mix['dnn'] = model.predict(X_eval_final)\n",
    "\n",
    "df_eval_mix['Predicted'] = df_eval_mix['lgbm'] *0.1 + df_eval_mix['dnn'] * 0.9\n",
    "df_eval_mix[['Predicted']].to_csv('dnn_lgbm_simplecombine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN To combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.2254 - binary_accuracy: 0.6641 - auc: 0.6060\n",
      "Epoch 00001: auc improved from -inf to 0.63723, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.2216 - binary_accuracy: 0.6647 - auc: 0.6372\n",
      "Epoch 2/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1660 - binary_accuracy: 0.6665 - auc: 0.8914\n",
      "Epoch 00002: auc improved from 0.63723 to 0.89184, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1648 - binary_accuracy: 0.6647 - auc: 0.8918\n",
      "Epoch 3/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1447 - binary_accuracy: 0.7751 - auc: 0.9036\n",
      "Epoch 00003: auc improved from 0.89184 to 0.90265, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1436 - binary_accuracy: 0.7847 - auc: 0.9026\n",
      "Epoch 4/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1363 - binary_accuracy: 0.8497 - auc: 0.9043\n",
      "Epoch 00004: auc improved from 0.90265 to 0.90368, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1359 - binary_accuracy: 0.8497 - auc: 0.9037\n",
      "Epoch 5/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1320 - binary_accuracy: 0.8496 - auc: 0.9030\n",
      "Epoch 00005: auc did not improve from 0.90368\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1311 - binary_accuracy: 0.8495 - auc: 0.9036\n",
      "Epoch 6/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1276 - binary_accuracy: 0.8495 - auc: 0.9066\n",
      "Epoch 00006: auc improved from 0.90368 to 0.90612, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1275 - binary_accuracy: 0.8497 - auc: 0.9061\n",
      "Epoch 7/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1251 - binary_accuracy: 0.8507 - auc: 0.9053\n",
      "Epoch 00007: auc did not improve from 0.90612\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1247 - binary_accuracy: 0.8508 - auc: 0.9060\n",
      "Epoch 8/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1229 - binary_accuracy: 0.8491 - auc: 0.9091\n",
      "Epoch 00008: auc improved from 0.90612 to 0.91030, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1224 - binary_accuracy: 0.8491 - auc: 0.9103\n",
      "Epoch 9/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1201 - binary_accuracy: 0.8511 - auc: 0.9134\n",
      "Epoch 00009: auc improved from 0.91030 to 0.91227, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1204 - binary_accuracy: 0.8499 - auc: 0.9123\n",
      "Epoch 10/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1191 - binary_accuracy: 0.8501 - auc: 0.9124\n",
      "Epoch 00010: auc improved from 0.91227 to 0.91306, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1188 - binary_accuracy: 0.8502 - auc: 0.9131\n",
      "Epoch 11/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1175 - binary_accuracy: 0.8498 - auc: 0.9134\n",
      "Epoch 00011: auc improved from 0.91306 to 0.91424, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1174 - binary_accuracy: 0.8499 - auc: 0.9142\n",
      "Epoch 12/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1162 - binary_accuracy: 0.8501 - auc: 0.9156\n",
      "Epoch 00012: auc improved from 0.91424 to 0.91487, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1161 - binary_accuracy: 0.8500 - auc: 0.9149\n",
      "Epoch 13/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1155 - binary_accuracy: 0.8490 - auc: 0.9133\n",
      "Epoch 00013: auc did not improve from 0.91487\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1150 - binary_accuracy: 0.8494 - auc: 0.9143\n",
      "Epoch 14/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1138 - binary_accuracy: 0.8507 - auc: 0.9164\n",
      "Epoch 00014: auc improved from 0.91487 to 0.91547, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1142 - binary_accuracy: 0.8498 - auc: 0.9155\n",
      "Epoch 15/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1129 - binary_accuracy: 0.8516 - auc: 0.9164\n",
      "Epoch 00015: auc improved from 0.91547 to 0.91573, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1135 - binary_accuracy: 0.8502 - auc: 0.9157\n",
      "Epoch 16/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1120 - binary_accuracy: 0.8501 - auc: 0.9155\n",
      "Epoch 00016: auc did not improve from 0.91573\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1126 - binary_accuracy: 0.8492 - auc: 0.9155\n",
      "Epoch 17/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1116 - binary_accuracy: 0.8507 - auc: 0.9178\n",
      "Epoch 00017: auc improved from 0.91573 to 0.91673, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1120 - binary_accuracy: 0.8498 - auc: 0.9167\n",
      "Epoch 18/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1118 - binary_accuracy: 0.8494 - auc: 0.9160\n",
      "Epoch 00018: auc did not improve from 0.91673\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1116 - binary_accuracy: 0.8493 - auc: 0.9165\n",
      "Epoch 19/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1117 - binary_accuracy: 0.8474 - auc: 0.9161\n",
      "Epoch 00019: auc improved from 0.91673 to 0.91707, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1109 - binary_accuracy: 0.8490 - auc: 0.9171\n",
      "Epoch 20/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1113 - binary_accuracy: 0.8489 - auc: 0.9154\n",
      "Epoch 00020: auc did not improve from 0.91707\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1105 - binary_accuracy: 0.8495 - auc: 0.9168\n",
      "Epoch 21/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1105 - binary_accuracy: 0.8495 - auc: 0.9158\n",
      "Epoch 00021: auc did not improve from 0.91707\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1102 - binary_accuracy: 0.8493 - auc: 0.9164\n",
      "Epoch 22/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1098 - binary_accuracy: 0.8496 - auc: 0.9174\n",
      "Epoch 00022: auc did not improve from 0.91707\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1098 - binary_accuracy: 0.8500 - auc: 0.9170\n",
      "Epoch 23/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1096 - binary_accuracy: 0.8504 - auc: 0.9171\n",
      "Epoch 00023: auc did not improve from 0.91707\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1095 - binary_accuracy: 0.8501 - auc: 0.9169\n",
      "Epoch 24/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1096 - binary_accuracy: 0.8497 - auc: 0.9170- ETA: 0s - loss: 0.1097 - binary_accuracy: 0.8520 - auc: 0.9\n",
      "Epoch 00024: auc improved from 0.91707 to 0.91715, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1091 - binary_accuracy: 0.8505 - auc: 0.9172\n",
      "Epoch 25/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1086 - binary_accuracy: 0.8504 - auc: 0.9180\n",
      "Epoch 00025: auc improved from 0.91715 to 0.91750, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1089 - binary_accuracy: 0.8498 - auc: 0.9175\n",
      "Epoch 26/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1091 - binary_accuracy: 0.8487 - auc: 0.9169\n",
      "Epoch 00026: auc improved from 0.91750 to 0.91754, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1088 - binary_accuracy: 0.8493 - auc: 0.9175\n",
      "Epoch 27/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1084 - binary_accuracy: 0.8506 - auc: 0.9175\n",
      "Epoch 00027: auc did not improve from 0.91754\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1084 - binary_accuracy: 0.8501 - auc: 0.9174\n",
      "Epoch 28/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1079 - binary_accuracy: 0.8498 - auc: 0.9181\n",
      "Epoch 00028: auc improved from 0.91754 to 0.91780, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1084 - binary_accuracy: 0.8492 - auc: 0.9178\n",
      "Epoch 29/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1079 - binary_accuracy: 0.8505 - auc: 0.9186\n",
      "Epoch 00029: auc improved from 0.91780 to 0.91824, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1081 - binary_accuracy: 0.8502 - auc: 0.9182\n",
      "Epoch 30/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1083 - binary_accuracy: 0.8490 - auc: 0.9180\n",
      "Epoch 00030: auc improved from 0.91824 to 0.91826, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1080 - binary_accuracy: 0.8498 - auc: 0.9183\n",
      "Epoch 31/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1083 - binary_accuracy: 0.8503 - auc: 0.9176\n",
      "Epoch 00031: auc did not improve from 0.91826\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1079 - binary_accuracy: 0.8505 - auc: 0.9180\n",
      "Epoch 32/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1080 - binary_accuracy: 0.8501 - auc: 0.9178\n",
      "Epoch 00032: auc did not improve from 0.91826\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1077 - binary_accuracy: 0.8505 - auc: 0.9182\n",
      "Epoch 33/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1078 - binary_accuracy: 0.8488 - auc: 0.9186\n",
      "Epoch 00033: auc improved from 0.91826 to 0.91862, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1076 - binary_accuracy: 0.8496 - auc: 0.9186\n",
      "Epoch 34/200\n",
      " 99/107 [==========================>...] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8508 - auc: 0.9191\n",
      "Epoch 00034: auc improved from 0.91862 to 0.91877, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1075 - binary_accuracy: 0.8500 - auc: 0.9188\n",
      "Epoch 35/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1074 - binary_accuracy: 0.8508 - auc: 0.9192\n",
      "Epoch 00035: auc improved from 0.91877 to 0.91882, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1074 - binary_accuracy: 0.8506 - auc: 0.9188\n",
      "Epoch 36/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1079 - binary_accuracy: 0.8494 - auc: 0.9177\n",
      "Epoch 00036: auc improved from 0.91882 to 0.91889, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1074 - binary_accuracy: 0.8498 - auc: 0.9189\n",
      "Epoch 37/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8507 - auc: 0.9191\n",
      "Epoch 00037: auc did not improve from 0.91889\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1072 - binary_accuracy: 0.8501 - auc: 0.9188\n",
      "Epoch 38/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1069 - binary_accuracy: 0.8502 - auc: 0.9193\n",
      "Epoch 00038: auc did not improve from 0.91889\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1072 - binary_accuracy: 0.8502 - auc: 0.9189\n",
      "Epoch 39/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8510 - auc: 0.9196\n",
      "Epoch 00039: auc improved from 0.91889 to 0.91918, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1071 - binary_accuracy: 0.8507 - auc: 0.9192\n",
      "Epoch 40/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8496 - auc: 0.9193\n",
      "Epoch 00040: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1071 - binary_accuracy: 0.8491 - auc: 0.9191\n",
      "Epoch 41/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1072 - binary_accuracy: 0.8510 - auc: 0.9190\n",
      "Epoch 00041: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1071 - binary_accuracy: 0.8509 - auc: 0.9191\n",
      "Epoch 42/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1074 - binary_accuracy: 0.8498 - auc: 0.9177\n",
      "Epoch 00042: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1071 - binary_accuracy: 0.8499 - auc: 0.9187\n",
      "Epoch 43/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8516 - auc: 0.9198\n",
      "Epoch 00043: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1069 - binary_accuracy: 0.8507 - auc: 0.9191\n",
      "Epoch 44/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8508 - auc: 0.9194\n",
      "Epoch 00044: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1069 - binary_accuracy: 0.8501 - auc: 0.9191\n",
      "Epoch 45/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8494 - auc: 0.9186\n",
      "Epoch 00045: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1068 - binary_accuracy: 0.8499 - auc: 0.9191\n",
      "Epoch 46/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1074 - binary_accuracy: 0.8489 - auc: 0.9188\n",
      "Epoch 00046: auc did not improve from 0.91918\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1070 - binary_accuracy: 0.8493 - auc: 0.9190\n",
      "Epoch 47/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8503 - auc: 0.9189\n",
      "Epoch 00047: auc improved from 0.91918 to 0.91941, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1068 - binary_accuracy: 0.8499 - auc: 0.9194\n",
      "Epoch 48/200\n",
      " 91/107 [========================>.....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8507 - auc: 0.9194\n",
      "Epoch 00048: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8505 - auc: 0.9193\n",
      "Epoch 49/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8523 - auc: 0.9206\n",
      "Epoch 00049: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1069 - binary_accuracy: 0.8511 - auc: 0.9193\n",
      "Epoch 50/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8501 - auc: 0.9192\n",
      "Epoch 00050: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8501 - auc: 0.9193\n",
      "Epoch 51/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8509 - auc: 0.9195\n",
      "Epoch 00051: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1068 - binary_accuracy: 0.8503 - auc: 0.9189\n",
      "Epoch 52/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8509 - auc: 0.9196\n",
      "Epoch 00052: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8502 - auc: 0.9193\n",
      "Epoch 53/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8496 - auc: 0.9182\n",
      "Epoch 00053: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8504 - auc: 0.9192\n",
      "Epoch 54/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8508 - auc: 0.9203\n",
      "Epoch 00054: auc did not improve from 0.91941\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1068 - binary_accuracy: 0.8498 - auc: 0.9192\n",
      "Epoch 55/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8502 - auc: 0.9188- ETA: 0s - loss: 0.1077 - binary_accuracy: 0.8491 - auc: 0.91\n",
      "Epoch 00055: auc improved from 0.91941 to 0.91958, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1066 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8513 - auc: 0.9190\n",
      "Epoch 00056: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8505 - auc: 0.9193\n",
      "Epoch 57/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8501 - auc: 0.9192\n",
      "Epoch 00057: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8500 - auc: 0.9194\n",
      "Epoch 58/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8520 - auc: 0.9199\n",
      "Epoch 00058: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1066 - binary_accuracy: 0.8504 - auc: 0.9195\n",
      "Epoch 59/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8503 - auc: 0.9195\n",
      "Epoch 00059: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8505 - auc: 0.9193\n",
      "Epoch 60/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8499 - auc: 0.9206\n",
      "Epoch 00060: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8498 - auc: 0.9195\n",
      "Epoch 61/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8495 - auc: 0.9193\n",
      "Epoch 00061: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1066 - binary_accuracy: 0.8500 - auc: 0.9195\n",
      "Epoch 62/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8503 - auc: 0.9201- ETA: 0s - loss: 0.1072 - binary_accuracy: 0.8484 - auc: 0.9\n",
      "Epoch 00062: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8505 - auc: 0.9194\n",
      "Epoch 63/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8506 - auc: 0.9198\n",
      "Epoch 00063: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1066 - binary_accuracy: 0.8501 - auc: 0.9191\n",
      "Epoch 64/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9197\n",
      "Epoch 00064: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1067 - binary_accuracy: 0.8500 - auc: 0.9193\n",
      "Epoch 65/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8498 - auc: 0.9190\n",
      "Epoch 00065: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8507 - auc: 0.9194\n",
      "Epoch 66/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8486 - auc: 0.9190\n",
      "Epoch 00066: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8495 - auc: 0.9195\n",
      "Epoch 67/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8497 - auc: 0.9196\n",
      "Epoch 00067: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8499 - auc: 0.9195\n",
      "Epoch 68/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8501 - auc: 0.9197\n",
      "Epoch 00068: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8499 - auc: 0.9194\n",
      "Epoch 69/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8503 - auc: 0.9196\n",
      "Epoch 00069: auc did not improve from 0.91958\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8500 - auc: 0.9195\n",
      "Epoch 70/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8489 - auc: 0.9186\n",
      "Epoch 00070: auc improved from 0.91958 to 0.91967, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8493 - auc: 0.9197\n",
      "Epoch 71/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8499 - auc: 0.9193\n",
      "Epoch 00071: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8504 - auc: 0.9192\n",
      "Epoch 72/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8493 - auc: 0.9193\n",
      "Epoch 00072: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8500 - auc: 0.9195\n",
      "Epoch 73/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8506 - auc: 0.9196\n",
      "Epoch 00073: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8508 - auc: 0.9193\n",
      "Epoch 74/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8507 - auc: 0.9203\n",
      "Epoch 00074: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8499 - auc: 0.9194\n",
      "Epoch 75/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8507 - auc: 0.9205\n",
      "Epoch 00075: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1066 - binary_accuracy: 0.8496 - auc: 0.9194\n",
      "Epoch 76/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8503 - auc: 0.9195\n",
      "Epoch 00076: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8504 - auc: 0.9194\n",
      "Epoch 77/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8495 - auc: 0.9193\n",
      "Epoch 00077: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8497 - auc: 0.9194\n",
      "Epoch 78/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8519 - auc: 0.9191\n",
      "Epoch 00078: auc did not improve from 0.91967\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8511 - auc: 0.9194\n",
      "Epoch 79/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8507 - auc: 0.9202\n",
      "Epoch 00079: auc improved from 0.91967 to 0.91972, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9197\n",
      "Epoch 80/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8503 - auc: 0.9192\n",
      "Epoch 00080: auc did not improve from 0.91972\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8507 - auc: 0.9195\n",
      "Epoch 81/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8482 - auc: 0.9187\n",
      "Epoch 00081: auc did not improve from 0.91972\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8496 - auc: 0.9194\n",
      "Epoch 82/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8497 - auc: 0.9199\n",
      "Epoch 00082: auc did not improve from 0.91972\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8493 - auc: 0.9196\n",
      "Epoch 83/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1057 - binary_accuracy: 0.8516 - auc: 0.9205\n",
      "Epoch 00083: auc did not improve from 0.91972\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8503 - auc: 0.9196\n",
      "Epoch 84/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8504 - auc: 0.9201\n",
      "Epoch 00084: auc did not improve from 0.91972\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 85/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8499 - auc: 0.9197\n",
      "Epoch 00085: auc did not improve from 0.91972\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8493 - auc: 0.9195\n",
      "Epoch 86/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8506 - auc: 0.9202\n",
      "Epoch 00086: auc improved from 0.91972 to 0.91975, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9197\n",
      "Epoch 87/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8519 - auc: 0.9203\n",
      "Epoch 00087: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9195\n",
      "Epoch 88/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8499 - auc: 0.9205\n",
      "Epoch 00088: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8496 - auc: 0.9197\n",
      "Epoch 89/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8508 - auc: 0.9195\n",
      "Epoch 00089: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 90/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1073 - binary_accuracy: 0.8491 - auc: 0.9179\n",
      "Epoch 00090: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8508 - auc: 0.9192\n",
      "Epoch 91/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1074 - binary_accuracy: 0.8487 - auc: 0.9184\n",
      "Epoch 00091: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8505 - auc: 0.9196\n",
      "Epoch 92/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8496 - auc: 0.9197\n",
      "Epoch 00092: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8499 - auc: 0.9195\n",
      "Epoch 93/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8520 - auc: 0.9204\n",
      "Epoch 00093: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8507 - auc: 0.9195\n",
      "Epoch 94/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8516 - auc: 0.9199\n",
      "Epoch 00094: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8508 - auc: 0.9195\n",
      "Epoch 95/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1069 - binary_accuracy: 0.8493 - auc: 0.9192\n",
      "Epoch 00095: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8499 - auc: 0.9196\n",
      "Epoch 96/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8502 - auc: 0.9195\n",
      "Epoch 00096: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8496 - auc: 0.9195\n",
      "Epoch 97/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8505 - auc: 0.9200\n",
      "Epoch 00097: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8501 - auc: 0.9197\n",
      "Epoch 98/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8511 - auc: 0.9200\n",
      "Epoch 00098: auc did not improve from 0.91975\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8499 - auc: 0.9194\n",
      "Epoch 99/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8478 - auc: 0.9189\n",
      "Epoch 00099: auc improved from 0.91975 to 0.91976, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8493 - auc: 0.9198\n",
      "Epoch 100/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1057 - binary_accuracy: 0.8510 - auc: 0.9204\n",
      "Epoch 00100: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 101/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8501 - auc: 0.9181\n",
      "Epoch 00101: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8506 - auc: 0.9194\n",
      "Epoch 102/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9194\n",
      "Epoch 00102: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8505 - auc: 0.9196\n",
      "Epoch 103/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8516 - auc: 0.9199\n",
      "Epoch 00103: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8511 - auc: 0.9195\n",
      "Epoch 104/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8511 - auc: 0.9200\n",
      "Epoch 00104: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9194\n",
      "Epoch 105/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8503 - auc: 0.9194\n",
      "Epoch 00105: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8509 - auc: 0.9195\n",
      "Epoch 106/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9193\n",
      "Epoch 00106: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8499 - auc: 0.9196\n",
      "Epoch 107/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8505 - auc: 0.9199\n",
      "Epoch 00107: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8503 - auc: 0.9197\n",
      "Epoch 108/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8507 - auc: 0.9194\n",
      "Epoch 00108: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 109/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8494 - auc: 0.9193\n",
      "Epoch 00109: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 110/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8495 - auc: 0.9191\n",
      "Epoch 00110: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8493 - auc: 0.9194\n",
      "Epoch 111/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1074 - binary_accuracy: 0.8498 - auc: 0.9182\n",
      "Epoch 00111: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8506 - auc: 0.9193\n",
      "Epoch 112/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8504 - auc: 0.9199\n",
      "Epoch 00112: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9195\n",
      "Epoch 113/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1056 - binary_accuracy: 0.8522 - auc: 0.9207\n",
      "Epoch 00113: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8506 - auc: 0.9194\n",
      "Epoch 114/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8509 - auc: 0.9202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00114: auc did not improve from 0.91976\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8497 - auc: 0.9197\n",
      "Epoch 115/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8510 - auc: 0.9200\n",
      "Epoch 00115: auc improved from 0.91976 to 0.91978, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8503 - auc: 0.9198\n",
      "Epoch 116/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8505 - auc: 0.9195\n",
      "Epoch 00116: auc did not improve from 0.91978\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9196\n",
      "Epoch 117/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1056 - binary_accuracy: 0.8510 - auc: 0.9204\n",
      "Epoch 00117: auc improved from 0.91978 to 0.91982, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8500 - auc: 0.9198\n",
      "Epoch 118/200\n",
      " 88/107 [=======================>......] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8511 - auc: 0.9198\n",
      "Epoch 00118: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9197\n",
      "Epoch 119/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1057 - binary_accuracy: 0.8521 - auc: 0.9203\n",
      "Epoch 00119: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8506 - auc: 0.9197\n",
      "Epoch 120/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9195\n",
      "Epoch 00120: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9197\n",
      "Epoch 121/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8509 - auc: 0.9201\n",
      "Epoch 00121: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8506 - auc: 0.9197\n",
      "Epoch 122/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8495 - auc: 0.9193\n",
      "Epoch 00122: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8501 - auc: 0.9195\n",
      "Epoch 123/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8503 - auc: 0.9193\n",
      "Epoch 00123: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8512 - auc: 0.9196\n",
      "Epoch 124/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8502 - auc: 0.9197\n",
      "Epoch 00124: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9198\n",
      "Epoch 125/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8485 - auc: 0.9191\n",
      "Epoch 00125: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8495 - auc: 0.9196\n",
      "Epoch 126/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8509 - auc: 0.9202\n",
      "Epoch 00126: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8505 - auc: 0.9197\n",
      "Epoch 127/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8485 - auc: 0.9187\n",
      "Epoch 00127: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8501 - auc: 0.9196\n",
      "Epoch 128/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8507 - auc: 0.9202\n",
      "Epoch 00128: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8499 - auc: 0.9197\n",
      "Epoch 129/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8503 - auc: 0.9193\n",
      "Epoch 00129: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8503 - auc: 0.9196\n",
      "Epoch 130/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8508 - auc: 0.9197\n",
      "Epoch 00130: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8499 - auc: 0.9193\n",
      "Epoch 131/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8510 - auc: 0.9201\n",
      "Epoch 00131: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8507 - auc: 0.9198\n",
      "Epoch 132/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 00132: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1062 - binary_accuracy: 0.8503 - auc: 0.9198\n",
      "Epoch 133/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8494 - auc: 0.9185\n",
      "Epoch 00133: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9197\n",
      "Epoch 134/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8501 - auc: 0.9194\n",
      "Epoch 00134: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9198\n",
      "Epoch 135/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1055 - binary_accuracy: 0.8512 - auc: 0.9208\n",
      "Epoch 00135: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8501 - auc: 0.9196\n",
      "Epoch 136/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8515 - auc: 0.9201\n",
      "Epoch 00136: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9197\n",
      "Epoch 137/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8502 - auc: 0.9197\n",
      "Epoch 00137: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8506 - auc: 0.9196\n",
      "Epoch 138/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8515 - auc: 0.9192\n",
      "Epoch 00138: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8508 - auc: 0.9194\n",
      "Epoch 139/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8497 - auc: 0.9195\n",
      "Epoch 00139: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 140/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8497 - auc: 0.9193\n",
      "Epoch 00140: auc did not improve from 0.91982\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9197\n",
      "Epoch 141/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8502 - auc: 0.9201\n",
      "Epoch 00141: auc improved from 0.91982 to 0.91985, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9198\n",
      "Epoch 142/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8511 - auc: 0.9204\n",
      "Epoch 00142: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8505 - auc: 0.9198\n",
      "Epoch 143/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8494 - auc: 0.9196\n",
      "Epoch 00143: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8497 - auc: 0.9201\n",
      "Epoch 00144: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8497 - auc: 0.9198\n",
      "Epoch 145/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8514 - auc: 0.9202\n",
      "Epoch 00145: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8509 - auc: 0.9197\n",
      "Epoch 146/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1073 - binary_accuracy: 0.8484 - auc: 0.9180\n",
      "Epoch 00146: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8499 - auc: 0.9196\n",
      "Epoch 147/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8495 - auc: 0.9193\n",
      "Epoch 00147: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8499 - auc: 0.9195\n",
      "Epoch 148/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8516 - auc: 0.9201\n",
      "Epoch 00148: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8505 - auc: 0.9198\n",
      "Epoch 149/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8503 - auc: 0.9193\n",
      "Epoch 00149: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8507 - auc: 0.9197\n",
      "Epoch 150/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1067 - binary_accuracy: 0.8497 - auc: 0.9191\n",
      "Epoch 00150: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 151/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8497 - auc: 0.9191\n",
      "Epoch 00151: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8505 - auc: 0.9196\n",
      "Epoch 152/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8492 - auc: 0.9195\n",
      "Epoch 00152: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8498 - auc: 0.9197\n",
      "Epoch 153/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8512 - auc: 0.9204\n",
      "Epoch 00153: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8503 - auc: 0.9196\n",
      "Epoch 154/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8513 - auc: 0.9201\n",
      "Epoch 00154: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9197\n",
      "Epoch 155/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1073 - binary_accuracy: 0.8484 - auc: 0.9182\n",
      "Epoch 00155: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1066 - binary_accuracy: 0.8505 - auc: 0.9192\n",
      "Epoch 156/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8508 - auc: 0.9198\n",
      "Epoch 00156: auc did not improve from 0.91985\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8507 - auc: 0.9196\n",
      "Epoch 157/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8509 - auc: 0.9201\n",
      "Epoch 00157: auc improved from 0.91985 to 0.91994, saving model to best_mix_model.h5\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9199\n",
      "Epoch 158/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8501 - auc: 0.9197\n",
      "Epoch 00158: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8500 - auc: 0.9197\n",
      "Epoch 159/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8485 - auc: 0.9194\n",
      "Epoch 00159: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8498 - auc: 0.9199\n",
      "Epoch 160/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8510 - auc: 0.9202\n",
      "Epoch 00160: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 161/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8509 - auc: 0.9202\n",
      "Epoch 00161: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8509 - auc: 0.9198\n",
      "Epoch 162/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1059 - binary_accuracy: 0.8504 - auc: 0.9205\n",
      "Epoch 00162: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8505 - auc: 0.9196\n",
      "Epoch 163/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8511 - auc: 0.9199\n",
      "Epoch 00163: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8507 - auc: 0.9198\n",
      "Epoch 164/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8516 - auc: 0.9193\n",
      "Epoch 00164: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1062 - binary_accuracy: 0.8514 - auc: 0.9198\n",
      "Epoch 165/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8512 - auc: 0.9197\n",
      "Epoch 00165: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8509 - auc: 0.9197\n",
      "Epoch 166/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8492 - auc: 0.9196\n",
      "Epoch 00166: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 167/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8511 - auc: 0.9200\n",
      "Epoch 00167: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8503 - auc: 0.9195\n",
      "Epoch 168/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8514 - auc: 0.9199\n",
      "Epoch 00168: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9198\n",
      "Epoch 169/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8508 - auc: 0.9195\n",
      "Epoch 00169: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8509 - auc: 0.9197\n",
      "Epoch 170/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8503 - auc: 0.9209\n",
      "Epoch 00170: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8505 - auc: 0.9199\n",
      "Epoch 171/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8515 - auc: 0.9203\n",
      "Epoch 00171: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8509 - auc: 0.9194\n",
      "Epoch 172/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8507 - auc: 0.9199\n",
      "Epoch 00172: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8503 - auc: 0.9197\n",
      "Epoch 173/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8503 - auc: 0.9198\n",
      "Epoch 00173: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8503 - auc: 0.9197\n",
      "Epoch 174/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8503 - auc: 0.9196\n",
      "Epoch 00174: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 175/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8499 - auc: 0.9195- ETA: 0s - loss: 0.1083 - binary_accuracy: 0.8475 - auc: 0.917\n",
      "Epoch 00175: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9197\n",
      "Epoch 176/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8493 - auc: 0.9195\n",
      "Epoch 00176: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8501 - auc: 0.9196\n",
      "Epoch 177/200\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8506 - auc: 0.9194\n",
      "Epoch 00177: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9198\n",
      "Epoch 178/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8501 - auc: 0.9191\n",
      "Epoch 00178: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8508 - auc: 0.9197\n",
      "Epoch 179/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8501 - auc: 0.9194\n",
      "Epoch 00179: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 180/200\n",
      " 91/107 [========================>.....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8503 - auc: 0.9200\n",
      "Epoch 00180: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8501 - auc: 0.9196\n",
      "Epoch 181/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8495 - auc: 0.9189\n",
      "Epoch 00181: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9197\n",
      "Epoch 182/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8514 - auc: 0.9203\n",
      "Epoch 00182: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9198\n",
      "Epoch 183/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1058 - binary_accuracy: 0.8511 - auc: 0.9203\n",
      "Epoch 00183: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8503 - auc: 0.9195\n",
      "Epoch 184/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8504 - auc: 0.9201\n",
      "Epoch 00184: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9199\n",
      "Epoch 185/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8503 - auc: 0.9193\n",
      "Epoch 00185: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9198\n",
      "Epoch 186/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1062 - binary_accuracy: 0.8510 - auc: 0.9200\n",
      "Epoch 00186: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8506 - auc: 0.9196\n",
      "Epoch 187/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1063 - binary_accuracy: 0.8506 - auc: 0.9197\n",
      "Epoch 00187: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8502 - auc: 0.9196\n",
      "Epoch 188/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1061 - binary_accuracy: 0.8509 - auc: 0.9197\n",
      "Epoch 00188: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1062 - binary_accuracy: 0.8504 - auc: 0.9199\n",
      "Epoch 189/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8498 - auc: 0.9194\n",
      "Epoch 00189: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1065 - binary_accuracy: 0.8501 - auc: 0.9194\n",
      "Epoch 190/200\n",
      " 90/107 [========================>.....] - ETA: 0s - loss: 0.1064 - binary_accuracy: 0.8518 - auc: 0.9189\n",
      "Epoch 00190: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8516 - auc: 0.9194\n",
      "Epoch 191/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1060 - binary_accuracy: 0.8509 - auc: 0.9204\n",
      "Epoch 00191: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8502 - auc: 0.9197\n",
      "Epoch 192/200\n",
      " 92/107 [========================>.....] - ETA: 0s - loss: 0.1070 - binary_accuracy: 0.8508 - auc: 0.9185\n",
      "Epoch 00192: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8512 - auc: 0.9197\n",
      "Epoch 193/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1055 - binary_accuracy: 0.8515 - auc: 0.9205\n",
      "Epoch 00193: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8500 - auc: 0.9197\n",
      "Epoch 194/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1069 - binary_accuracy: 0.8491 - auc: 0.9191\n",
      "Epoch 00194: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9196\n",
      "Epoch 195/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1075 - binary_accuracy: 0.8480 - auc: 0.9186\n",
      "Epoch 00195: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8504 - auc: 0.9195\n",
      "Epoch 196/200\n",
      " 94/107 [=========================>....] - ETA: 0s - loss: 0.1071 - binary_accuracy: 0.8487 - auc: 0.9185\n",
      "Epoch 00196: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9198\n",
      "Epoch 197/200\n",
      " 93/107 [=========================>....] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8504 - auc: 0.9192\n",
      "Epoch 00197: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8508 - auc: 0.9198\n",
      "Epoch 198/200\n",
      " 96/107 [=========================>....] - ETA: 0s - loss: 0.1065 - binary_accuracy: 0.8509 - auc: 0.9193\n",
      "Epoch 00198: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.8510 - auc: 0.9195\n",
      "Epoch 199/200\n",
      " 95/107 [=========================>....] - ETA: 0s - loss: 0.1068 - binary_accuracy: 0.8498 - auc: 0.9191\n",
      "Epoch 00199: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8505 - auc: 0.9196\n",
      "Epoch 200/200\n",
      " 97/107 [==========================>...] - ETA: 0s - loss: 0.1066 - binary_accuracy: 0.8502 - auc: 0.9193\n",
      "Epoch 00200: auc did not improve from 0.91994\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.1063 - binary_accuracy: 0.8504 - auc: 0.9199\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import AUC\n",
    "auc = AUC(name='auc')\n",
    "\n",
    "FEATURES = 2\n",
    "\n",
    "mix_model = Sequential()\n",
    "mix_model.add(Dense(FEATURES*8, input_dim=FEATURES, activation='relu'))\n",
    "mix_model.add(Dense(FEATURES*4, activation='relu'))\n",
    "mix_model.add(Dense(FEATURES*2, activation='relu'))\n",
    "# OUTPUT\n",
    "mix_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Early Stopping\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "# es = EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=50)\n",
    "# Store best model\n",
    "mc = ModelCheckpoint('best_mix_model.h5', monitor='auc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "mix_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy', auc])\n",
    "\n",
    "X_train = df_mix[['lgbm','dnn']]\n",
    "y_train = df_mix.target\n",
    "\n",
    "history = mix_model.fit(X_train, y_train, epochs=200, batch_size=200, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_final = pd.DataFrame(data=scaler.fit_transform(X_eval), columns=X_eval.columns)\n",
    "\n",
    "df_eval_mix_dnn = pd.read_csv('lgbm_eval_proba.csv', index_col=0)\n",
    "df_eval_mix_dnn['dnn'] = model.predict(X_eval_final)\n",
    "\n",
    "# Mix the two scores with the best mix model\n",
    "mix_model = load_model('best_mix_model.h5')\n",
    "df_eval_mix_dnn['Predicted'] = mix_model.predict(df_eval_mix_dnn[['lgbm','dnn']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_mix_dnn[['Predicted']].to_csv('dnn_lgbm_dnncombine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DNN Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_final = pd.DataFrame(data=scaler.fit_transform(X_eval), columns=X_eval.columns)\n",
    "\n",
    "y_hat_eval = model.predict(X_eval_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_hat_eval[y_hat_eval >= 0.5]), len(y_hat_eval[y_hat_eval < 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = pd.DataFrame(\n",
    "#     data=Binarizer(threshold=0.5).transform(y_hat_eval), \n",
    "    data=y_hat_eval, \n",
    "    columns=['Predicted'])\n",
    "df_predicted.to_csv(BEST_MODEL+'_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['signal']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
